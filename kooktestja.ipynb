{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total image files: 1795\n",
      "Model accuracy: 0.7632311977715878\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "import git\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img, array_to_img\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import randint\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def make_dataset(size=28):\n",
    "    repo_url = \"https://github.com/pongsapaks/Thai-handwrittingnumberproject.git\"\n",
    "    repo_dir = \"Thai-handwrittingnumberproject\"\n",
    "    subprocess.run([\"git\", \"clone\", repo_url, repo_dir])\n",
    "\n",
    "    image_dir = os.path.join(repo_dir, \"raw\")\n",
    "    image_files = []\n",
    "    for root, dirs, files in os.walk(image_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".png\"):\n",
    "                image_files.append(os.path.join(root, file))\n",
    "\n",
    "    print(\"Total image files:\", len(image_files))\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for image_path in image_files:\n",
    "        img = cv2.imread(image_path)\n",
    "        img = Image.open(image_path).convert(\"L\")\n",
    "        img = ImageOps.invert(img)\n",
    "        img = img.resize((size, size))\n",
    "        label = os.path.basename(os.path.dirname(image_path))\n",
    "        x = np.array(img)\n",
    "        X.append(x)\n",
    "        Y.append(label)\n",
    "\n",
    "    X = np.asarray(X)\n",
    "    Y = np.asarray(Y)\n",
    "\n",
    "    reshaped_X = X.reshape((X.shape[0], -1))\n",
    "    Ydf = pd.DataFrame(Y)\n",
    "    Xdf = pd.DataFrame(reshaped_X)\n",
    "\n",
    "    X_mean = Xdf.mean()\n",
    "    X_std = Xdf.std()\n",
    "    Z = (Xdf - X_mean) / X_std\n",
    "    Z = Z.fillna(0)\n",
    "\n",
    "    with open(\"std_params.pkl\", \"wb\") as f:\n",
    "        pickle.dump((X_mean, X_std), f)\n",
    "\n",
    "    pca = PCA(n_components=0.75)\n",
    "    pca.fit(Z)\n",
    "    X_pca = pca.transform(Z)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_pca, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    sv = SVC(C=10, gamma=0.001, kernel='rbf')\n",
    "    sv.fit(X_train, y_train)\n",
    "    pred = sv.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    print(f\"Model accuracy: {accuracy}\")\n",
    "\n",
    "    with open(\"model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(sv, f)\n",
    "    with open(\"pca.pkl\", \"wb\") as f:\n",
    "        pickle.dump(pca, f)\n",
    "make_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def preprocess_image(image_path, size=28):\n",
    "    img = Image.open(image_path).convert(\"L\")\n",
    "    img = ImageOps.invert(img)\n",
    "    img = img.resize((size, size))\n",
    "    img_arr = np.array(img)\n",
    "    return img_arr\n",
    "\n",
    "def predict_image(image_path, model_path=\"model.pkl\", pca_path=\"pca.pkl\", std_params_path=\"std_params.pkl\", size=28):\n",
    "    # Load the model, pca, and standardization parameters from files\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    with open(pca_path, 'rb') as f:\n",
    "        pca = pickle.load(f)\n",
    "    with open(std_params_path, 'rb') as f:\n",
    "        X_mean, X_std = pickle.load(f)\n",
    "\n",
    "    # Preprocess the image\n",
    "    image = preprocess_image(image_path, size=size)\n",
    "\n",
    "    # Flatten and standardize the image\n",
    "    reshaped_image = image.reshape((1, -1))\n",
    "    # Avoid division by zero by adding a small constant to X_std\n",
    "    epsilon = 1e-8\n",
    "    standardized_image = (reshaped_image - np.array(X_mean).reshape(1,-1)) / (np.array(X_std).reshape(1,-1) + epsilon)\n",
    "\n",
    "    if np.isnan(standardized_image).any():\n",
    "        print(\"standardized_image still contains NaN values!\")\n",
    "\n",
    "    # Apply PCA\n",
    "    transformed_image = pca.transform(standardized_image)\n",
    "\n",
    "    # Predict the label\n",
    "    prediction = model.predict(transformed_image)\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted label is: 6\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "\n",
    "image_path = r'C:\\Users\\Karuntarat\\OneDrive\\1st year\\1st Year, 2nd Term\\DADs6003 - ML\\Thai HandWriting\\Thai-handwrittingnumberproject\\3d0e872f-4def-4d84-823f-9c5606f7f672.png'  # replace with the actual path to your image\n",
    "prediction = predict_image(image_path)\n",
    "print(\"The predicted label is:\", prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Karuntarat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3441: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash_canvas import DashCanvas\n",
    "import dash_bootstrap_components as dbc\n",
    "import requests\n",
    "\n",
    "# Initialize the Flask app\n",
    "server = Flask(__name__)\n",
    "\n",
    "@server.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json(force=True)\n",
    "    image_data = data['image']\n",
    "    image_data = base64.b64decode(image_data.split(',')[1])\n",
    "    image = Image.open(BytesIO(image_data))\n",
    "\n",
    "    # preprocess and predict\n",
    "    prediction = predict_image(image) # Modify this line to suit the preprocessing and prediction in your case\n",
    "    return str(prediction)\n",
    "\n",
    "# Initialize the Dash app\n",
    "external_stylesheets = [dbc.themes.BOOTSTRAP]\n",
    "app = dash.Dash(__name__, server=server, external_stylesheets=external_stylesheets) # server=server connects Dash to Flask\n",
    "\n",
    "canvas_width = 500\n",
    "\n",
    "app.layout = html.Div([\n",
    "    DashCanvas(id='canvas',\n",
    "               lineWidth=5,\n",
    "               width=canvas_width,\n",
    "               ),\n",
    "    html.Button('Predict', id='button_predict', n_clicks=0),\n",
    "    html.Div(id='prediction')\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    dash.dependencies.Output('prediction', 'children'),\n",
    "    [dash.dependencies.Input('button_predict', 'n_clicks')],\n",
    "    [dash.dependencies.State('canvas', 'json_data')]\n",
    ")\n",
    "def update_output(n_clicks, json_data):\n",
    "    if n_clicks > 0:\n",
    "        image_data = json_data['image']\n",
    "        response = requests.post('http://localhost:5000/predict', json={'image': image_data})\n",
    "        return 'Predicted number: {}'.format(response.text)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV(4.7.0) d:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<3,4,-1>,struct cv::impl::A0x981fb336::Set<1,-1,-1>,struct cv::impl::A0x981fb336::Set<0,2,5>,2>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n",
      "> Invalid number of channels in input image:\n",
      ">     'VScn::contains(scn)'\n",
      "> where\n",
      ">     'scn' is 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "from PIL import ImageOps\n",
    "\n",
    "# Load the pre-trained model and PCA\n",
    "sv = joblib.load(\"model.pkl\")\n",
    "pca = joblib.load(\"pca.pkl\")\n",
    "\n",
    "# Load the mean and standard deviation for feature scaling\n",
    "X_mean = np.load(\"X_mean.npy\")\n",
    "X_std = np.load(\"X_std.npy\")\n",
    "\n",
    "def recognize_handwriting(img):\n",
    "    try:\n",
    "        # Preprocess the user input image\n",
    "        img_gray = cv2.cvtColor(np.array(img), cv2.COLOR_BGR2GRAY)\n",
    "        img_resized = cv2.resize(img_gray, (28, 28))\n",
    "        x = img_resized.flatten().reshape(1, -1)\n",
    "        x_scaled = (x - X_mean) / X_std\n",
    "        x_pca = pca.transform(x_scaled)\n",
    "        prediction = sv.predict(x_pca)[0]\n",
    "\n",
    "        return f\"The predicted digit is: {prediction}\"\n",
    "    except Exception as e:\n",
    "        print(e)  # Optional: print the error message to the console\n",
    "        return \"Character not recognized\"\n",
    "\n",
    "iface = gr.Interface(fn=recognize_handwriting, inputs=\"sketchpad\", outputs=\"label\")\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV(4.7.0) d:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<3,4,-1>,struct cv::impl::A0x981fb336::Set<1,-1,-1>,struct cv::impl::A0x981fb336::Set<0,2,5>,2>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n",
      "> Invalid number of channels in input image:\n",
      ">     'VScn::contains(scn)'\n",
      "> where\n",
      ">     'scn' is 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "from PIL import ImageOps\n",
    "\n",
    "# Load the pre-trained model and PCA\n",
    "sv = joblib.load(\"model.pkl\")\n",
    "pca = joblib.load(\"pca.pkl\")\n",
    "\n",
    "# Load the mean and standard deviation for feature scaling\n",
    "X_mean = np.load(\"X_mean.npy\")\n",
    "X_std = np.load(\"X_std.npy\")\n",
    "\n",
    "def preprocess_image(img):\n",
    "    # Convert to grayscale\n",
    "    img_gray = cv2.cvtColor(np.array(img), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply adaptive histogram equalization\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    img_equalized = clahe.apply(img_gray)\n",
    "\n",
    "    # Apply thresholding\n",
    "    _, img_thresholded = cv2.threshold(img_equalized, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Resize and reshape\n",
    "    img_resized = cv2.resize(img_thresholded, (28, 28))\n",
    "    x = img_resized.flatten().reshape(1, -1)\n",
    "\n",
    "    return x\n",
    "\n",
    "def recognize_handwriting(img):\n",
    "    try:\n",
    "        # Preprocess the user input image\n",
    "        ##x_scaled = (preprocess_image(img) - X_mean) / X_std\n",
    "        x_scaled = preprocess_image(img)\n",
    "        x_pca = pca.transform(x_scaled)\n",
    "        prediction = sv.predict(x_pca)[0]\n",
    "        return f\"The predicted digit is: {prediction}\"\n",
    "    except Exception as e:\n",
    "        print(e)  # Optional: print the error message to the console\n",
    "        return \"Character not recognized\"\n",
    "\n",
    "iface = gr.Interface(fn=recognize_handwriting, inputs=\"sketchpad\", outputs=\"label\")\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
